{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9bc3c8b2-35fb-44c3-800e-ef9bc13a9231",
      "metadata": {
        "id": "9bc3c8b2-35fb-44c3-800e-ef9bc13a9231"
      },
      "source": [
        "# Decoding CTC output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b923207-7a92-47f3-9f8f-1448b2ba4285",
      "metadata": {
        "id": "4b923207-7a92-47f3-9f8f-1448b2ba4285"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "\n",
        "# Load precomputed CTC output\n",
        "with open('mystery_records.pickle', 'rb') as f:\n",
        "    batch = pickle.load(f)\n",
        "\n",
        "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
        "log_probs = batch[\"log_probs\"]\n",
        "\n",
        "# Dictionary with index to character mapping\n",
        "ind2char = batch[\"ind2char\"]\n",
        "\n",
        "# Index of special EMPTY token\n",
        "EMPTY_TOK = '^'\n",
        "EMPTY_IND = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "922cbf65-fbaf-48d5-8605-ea41c3f80590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "922cbf65-fbaf-48d5-8605-ea41c3f80590",
        "outputId": "4622e200-b65f-4d76-bcbe-e23beae02e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0) w e   n o s t r n g e s t o   l o v e   y o u   k n o w   t h e r o l s   a n d   s o   d o   i   a   f o l   c o m i t m e n t   w h a t   i   t h i n k i n g   o f   y o u   w o l d e n   g e t   t h i s   f r o m   a n y   a t h e r   g u y\n",
            "1)   n e v e r   g o n a   g i v e   y o u   u p   n e v e r   d o n e l e t   y o u   d o w n   n e v e r   g o   a r u n   a r o u n d   a n d   d e s e t   y o u   n e v e r   g o n   a   m a k e   y o u   c r i   n e v e r   g o n a   s a y   g o d   b y\n"
          ]
        }
      ],
      "source": [
        "def ctc_decode(inds, ind2char):\n",
        "  result = []\n",
        "  last_char = EMPTY_TOK\n",
        "  for ind in inds:\n",
        "    if ind == EMPTY_IND:\n",
        "      continue\n",
        "    if last_char == ind2char[ind]:\n",
        "      continue\n",
        "    result.append(ind2char[ind])\n",
        "    # if ind == EMPTY_IND:\n",
        "    #   last_char = ind2char[ind]\n",
        "    #   continue\n",
        "    # if last_char != ind2char[ind]:\n",
        "    #   result.append(ind2char[ind])\n",
        "    last_char = ind2char[ind]\n",
        "  return \" \".join(result)\n",
        "\n",
        "for i, rec in enumerate(log_probs):\n",
        "    text = ctc_decode(rec.argmax(-1).numpy(), ind2char)\n",
        "    print(f\"{i}) {text}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a8c4d50-e633-4e85-8842-a6b50602b70f",
      "metadata": {
        "id": "3a8c4d50-e633-4e85-8842-a6b50602b70f"
      },
      "source": [
        "# Computing WER and CER\n",
        "Task: Implemet WER and CER metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "  WER = \\frac{S + D + I}{N}\n",
        "$$"
      ],
      "metadata": {
        "id": "_p-sU8ocmhXF"
      },
      "id": "_p-sU8ocmhXF"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0ca11f70-ee02-4765-b542-96186781a0b8",
      "metadata": {
        "id": "0ca11f70-ee02-4765-b542-96186781a0b8"
      },
      "outputs": [],
      "source": [
        "# library for fast quick calculation of edit distance\n",
        "import editdistance\n",
        "\n",
        "def calc_wer(target_text: str, pred_text: str):\n",
        "    if not target_text: ### case if we don't want to recognize speech (TV show sounds)\n",
        "      if pred_text:\n",
        "        return 1\n",
        "      return 0\n",
        "    list_target = target_text.split(\" \")\n",
        "    list_pred = pred_text.split(\" \")\n",
        "    return editdistance.eval(list_target, list_pred) / len(list_target)\n",
        "\n",
        "\n",
        "\n",
        "def calc_cer(target_text: str, pred_text: str):\n",
        "    return editdistance.eval(target_text, pred_text) / len(target_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6c391511-7469-4ed8-bd26-057c4fde4717",
      "metadata": {
        "id": "6c391511-7469-4ed8-bd26-057c4fde4717"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "for target, pred, expected_wer, expected_cer in [\n",
        "    (\"if you can not measure it you can not improve it\",\n",
        "     \"if you can nt measure t yo can not i\",\n",
        "     0.454, 0.25),\n",
        "    (\"if you cant describe what you are doing as a process you dont know what youre doing\",\n",
        "     \"if you cant describe what you are doing as a process you dont know what youre doing\",\n",
        "     0.0, 0.0),\n",
        "    (\"one measurement is worth a thousand expert opinions\",\n",
        "     \"one  is worth thousand opinions\",\n",
        "     0.375, 0.392)\n",
        "]:\n",
        "    wer = calc_wer(target, pred)\n",
        "    cer = calc_cer(target, pred)\n",
        "    assert np.isclose(wer, expected_wer, atol=1e-3), f\"true: {target}, pred: {pred}, expected wer {expected_wer} != your wer {wer}\"\n",
        "    assert np.isclose(cer, expected_cer, atol=1e-3), f\"true: {target}, pred: {pred}, expected cer {expected_cer} != your cer {cer}\"\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cefd76b-66d4-4b1e-ae1d-be6b7336a160",
      "metadata": {
        "id": "7cefd76b-66d4-4b1e-ae1d-be6b7336a160"
      },
      "source": [
        "Task: come up with such a pair of target-prediction texts, so the\n",
        "1) WER > 1.0\n",
        "2) CER > WER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "11bceaaf-7b17-466b-ac17-855e4d54cf56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11bceaaf-7b17-466b-ac17-855e4d54cf56",
        "outputId": "b1818d0f-33c0-499d-b66c-b3a1725bc5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "1.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "# 1) WER > 1.0\n",
        "target, prediction = \"a\" , \"a b bdb\"\n",
        "assert calc_wer(target, prediction) > 1.0\n",
        "\n",
        "# 2) CER > WER\n",
        "# your code here\n",
        "target, prediction = \"cat\", \"abcs\"\n",
        "assert calc_wer(target, prediction) < calc_cer(target, prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a1fb97-4853-4190-835d-31ead094679c",
      "metadata": {
        "id": "31a1fb97-4853-4190-835d-31ead094679c"
      },
      "source": [
        "# Beam search\n",
        "Task: implement beam-search on CTC outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f8e1c37a-93be-47a1-8211-9b47d0721d23",
      "metadata": {
        "id": "f8e1c37a-93be-47a1-8211-9b47d0721d23"
      },
      "outputs": [],
      "source": [
        "# Load precomputed CTC output\n",
        "with open('lj_batch.pickle', 'rb') as f:\n",
        "    batch = pickle.load(f)\n",
        "\n",
        "# log probabilities of softmax layers [batch_size, T, vocab_size]\n",
        "log_probs = batch[\"log_probs\"]\n",
        "\n",
        "# Dictionary with index to character mapping\n",
        "ind2char = batch[\"ind2char\"]\n",
        "\n",
        "true_texts = batch[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9ae1f264-33cb-4c4d-b959-823d07843936",
      "metadata": {
        "id": "9ae1f264-33cb-4c4d-b959-823d07843936"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "def extand_and_merge(frame, state, ind2char):\n",
        "  new_state = defaultdict(float)\n",
        "  for next_ind, next_proba in enumerate(frame):\n",
        "    for (pref, last_char), pref_proba in state.items():\n",
        "      next_char = ind2char[next_ind]\n",
        "      if next_char == last_char:\n",
        "        new_pref = pref\n",
        "      else:\n",
        "        if next_char != EMPTY_TOK:\n",
        "          new_pref = pref + next_char\n",
        "        else:\n",
        "          new_pref = pref\n",
        "        last_char = next_char\n",
        "      new_state[(new_pref, last_char)] += pref_proba * next_proba\n",
        "  return new_state\n",
        "\n",
        "def truncate(state, beam_size):\n",
        "    state_list = list(state.items())\n",
        "    state_list.sort(key=lambda x: -x[1])\n",
        "    return dict(state_list[:beam_size])\n",
        "\n",
        "\n",
        "def ctc_beam_search(probs, beam_size, ind2char):\n",
        "    state = {(\"\", EMPTY_TOK) : 1.0}\n",
        "    for frame in probs:\n",
        "      state = extand_and_merge(frame, state, ind2char)\n",
        "      state = truncate(state, beam_size)\n",
        "    return [[v[0][0], v[-1]] for v in list(state.items())]\n",
        "bs_results = []\n",
        "for log_probs_line in log_probs:\n",
        "    bs_results.append(ctc_beam_search(log_probs_line.exp().numpy(), 100, ind2char))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9e6d7249-aed1-4ff3-8ce2-20978320ac7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e6d7249-aed1-4ff3-8ce2-20978320ac7d",
        "outputId": "56efafb7-a68b-427b-c7f5-add73cf4853d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True:  he would go to her and tell her all his family complications\n",
            "Argmax: h e   w l d   g e   t o h e r   i a n d   t e l   h e r   a l   m h i s a n   l y   o m b l i c a t i o n s --- (CER: 0.983)\n",
            "1) 'he wl ge to her iand tell her all hisan ly omblications' --- (CER: 0.183)\n",
            "2) 'he wl ge to her and tell her all hisan ly omblications' --- (CER: 0.167)\n",
            "3) 'he wl ge to her iand tell her all hisanly omblications' --- (CER: 0.183)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  he did not say the last as a boast but merely as an assurance to the liveryman who he saw was anxious on his account\n",
            "Argmax: h e   d i d   n o t   s a d   t h e   l a s t   i s   a   b o s t   b u t   m e a r l i o v e s   a n   a s u r a n c e   t o   t h e   l i v e r y   m a n   w h o   r e   s a w   w a s   a n x e s   o n   h i s   a c o u n t --- (CER: 1.043)\n",
            "1) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.112)\n",
            "2) 'he did not say the last as a bost but merli oves an a surance to the livery man who re saw was anxes on his account' --- (CER: 0.103)\n",
            "3) 'he did not say the last is a bost but merli oves an a surance to the livery man who re saw was anxies on his account' --- (CER: 0.103)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  he started to conscious confusion only neither knowing where he was nor what he did\n",
            "Argmax: h e   s t a r t e d   t o   c o n s c e s   c o n f u s i o n   o n l y   n e i t h e r   k n o w i n g   w h e r e   h e   w a s   n o r   w h a t   h e   d i d --- (CER: 0.976)\n",
            "1) 'he started to consces confusion only neither knowing where he was nor what he did' --- (CER: 0.036)\n",
            "2) 'he started to consces confusion only neither knowwing where he was nor what he did' --- (CER: 0.048)\n",
            "3) 'he started to consces confusion only neither knowing where he was nor what he did ' --- (CER: 0.048)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  i'm here because the matter is of utmost importance and brandd is the one i must see now stand aside\n",
            "Argmax: i m c e r e   b e c a u s e   h e   m a t d e r a c i s   o f   u t   m o s t   o m p o r t a n c e a n d   b r a n d   i s   o   v a m a s e a   n h o s t e n d   a s i d e --- (CER: 0.940)\n",
            "1) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nho stend aside' --- (CER: 0.260)\n",
            "2) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhostend aside' --- (CER: 0.270)\n",
            "3) 'im chere because he matderacis of ut most omportanceand brand is o vamasea nhestend aside' --- (CER: 0.270)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  of course it ain't said missus bozzle\n",
            "Argmax: o f   c o u r s i t   i n t   s a i d   m i s u s   b o z o l --- (CER: 0.865)\n",
            "1) 'of cours it int said missus bozol' --- (CER: 0.135)\n",
            "2) 'of cours it int said missus bozol ' --- (CER: 0.135)\n",
            "3) 'of cours it int said missus bozal' --- (CER: 0.135)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  mister verloc was fully responsive now\n",
            "Argmax: m i s t e r   v o l o c k w a s   f u l y   r e s p o n s   o f   m o w --- (CER: 1.053)\n",
            "1) 'mister volockwass fuly respons of mow' --- (CER: 0.237)\n",
            "2) 'mister volockwass fuli respons of mow' --- (CER: 0.263)\n",
            "3) 'mister volockwass fuly resplons of mow' --- (CER: 0.263)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  oh what shall we do for a home\n",
            "Argmax: o h   w h a t   s h a l   w e   d o   f o r   a   w h o m --- (CER: 1.000)\n",
            "1) 'oh what shal we do for a whom' --- (CER: 0.100)\n",
            "2) 'ohh what shal we do for a whom' --- (CER: 0.133)\n",
            "3) 'oh what shal we do for a whom ' --- (CER: 0.100)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  line of battle was formed on the north bank of stone's river on the yankee side\n",
            "Argmax: l i n e   o f   b a t l e   w a s   f o r m e d   o n   t h e   n o r t h   b a n k   o f   s t o n e s   r i v e r   o n   t h e   y a n k y   s i d t   --- (CER: 1.000)\n",
            "1) 'wine of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.063)\n",
            "2) 'line of battle was formed on the north bank of stones river on the yanky side ' --- (CER: 0.051)\n",
            "3) 'wine of battle was formed on the north bank of stones river on the yanky side' --- (CER: 0.051)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  from fifteen to twenty minutes will be required to bake them nicely\n",
            "Argmax: f r o r   f i f t e n   t   t e n y   m i n i t e s   w i l   b e   r e q u i r e d   t o   b a k e   t h e   n i c e l y --- (CER: 0.925)\n",
            "1) 'fror fifteengt tweny minites will be required to bake the nicely' --- (CER: 0.090)\n",
            "2) 'fror fifteen t tweny minites will be required to bake the nicely' --- (CER: 0.075)\n",
            "3) 'fror fifteengt tweny minutes will be required to bake the nicely' --- (CER: 0.075)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "True:  whom is he going to flog now\n",
            "Argmax: w h o m   i s   a g o i n g   t o   f l a g   n o --- (CER: 0.929)\n",
            "1) 'whoom is agoing to flagd now' --- (CER: 0.214)\n",
            "2) 'whoom is agoing to flogd now' --- (CER: 0.179)\n",
            "3) 'whoom is agoing to flaugd now' --- (CER: 0.250)\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(len(true_texts)):\n",
        "    beam_search_hypos = bs_results[i][:3]\n",
        "    true_text = true_texts[i]\n",
        "    argmax_text = ctc_decode(log_probs[i].numpy().argmax(-1), ind2char)\n",
        "    print(\"True: \", true_text)\n",
        "    print(f\"Argmax: {argmax_text} --- (CER: {calc_cer(true_text, argmax_text):.3f})\")\n",
        "    for ind, (hypo, score) in enumerate(beam_search_hypos):\n",
        "        print(f\"{ind+1}) '{hypo}' --- (CER: {calc_cer(true_text, hypo):.3f})\")\n",
        "    print('-' * 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KAZueka1vRu6"
      },
      "id": "KAZueka1vRu6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "HW-ASR",
      "language": "python",
      "name": "hw-asr"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}